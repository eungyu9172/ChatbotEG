from langchain_core.messages import SystemMessage, HumanMessage

from states import ChatState
from config import PROCESSING_STAGES
from prompts import SYSTEM_PROMPTS
from utils.llm_clients import gpt_4o_with_tools
from utils.token_counter import count_tokens
from utils.logger import logger


def direct_answer(state: ChatState) -> ChatState:
    """ë‹¨ìˆœ ì¿¼ë¦¬ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
    messages = state.get("messages", [])
    logger.info(f"[Direct Answer] messages: {messages}")
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            user_message = msg
            break
    logger.info(f"[Direct Answer] ì§ì ‘ ë‹µë³€ ìƒì„± ì‹œì‘: {user_message.content}")
    logger.debug(f"[Direct Answer] ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬: {len(messages)}ê°œ")

    if user_message:
        last_msg_type = type(user_message).__name__
        logger.debug(f"[Direct Answer] ìœ ì € ë©”ì‹œì§€: '{last_msg_type}', {user_message.content}")

    system_prompt = SystemMessage(content=SYSTEM_PROMPTS["direct_answer"])
    prompt = [system_prompt] + messages

    # í† í° ìˆ˜ ë¡œê¹…
    total_prompt_tokens = sum(count_tokens(getattr(msg, 'content', str(msg))) for msg in prompt)
    logger.debug(f"[Direct Answer] ì „ì²´ í”„ë¡¬í”„íŠ¸ í† í°: {total_prompt_tokens}")

    response = gpt_4o_with_tools.invoke(prompt)

    # Tool í˜¸ì¶œ ì •ë³´ ë¡œê¹…
    tool_calls = getattr(response, 'tool_calls', None)
    if tool_calls:
        logger.info(f"[Direct Answer] ğŸ”§ ë„êµ¬ í˜¸ì¶œ ìš”ì²­ë¨: {len(tool_calls)}ê°œ")
        for i, tool_call in enumerate(tool_calls):
            tool_name = tool_call.get('name', 'unknown')
            tool_args = tool_call.get('args', {})
            logger.debug(f"[Direct Answer] ë„êµ¬ {i+1}: {tool_name}({tool_args})")
        logger.info(f"[Direct Answer] Response: {response}")
        return {
            "messages": [response],
            "tool_call_count": state.get("tool_call_count", 0) + 1,
            "processing_stage": PROCESSING_STAGES["TOOLS_NEEDED"]
        }
    else:
        response_tokens = count_tokens(response.content) if response.content else 0
        logger.info("âœ… [Direct Answer] ì§ì ‘ ë‹µë³€ ìƒì„±ë¨ (ë„êµ¬ í˜¸ì¶œ ì—†ìŒ)")
        logger.debug(f"[Direct Answer] ë‹µë³€ ê¸¸ì´: {len(response.content)}ì ({response_tokens} í† í°)")
        logger.info(f"[Direct Answer] Response: {response}")
        return {
            "final_answer": response.content or "",
            "messages": [response],
            "processing_stage": PROCESSING_STAGES["ANSWERED_DIRECT"]
        }
